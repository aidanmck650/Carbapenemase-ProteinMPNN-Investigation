{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "18ixWvqXhIZhBKF0soW6P9MBdkre4w3V0",
      "authorship_tag": "ABX9TyMAvEps7dyP8uNpYs1BK/h7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidanmck650/Carbapenemase-ProteinMPNN-Investigation/blob/main/CNN_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install captum"
      ],
      "metadata": {
        "id": "eWX-5xP7DHuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpyMfj6cWtJx"
      },
      "outputs": [],
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "import dask.array as da\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.model_selection import StratifiedGroupKFold, StratifiedShuffleSplit\n",
        "from torch.utils.data import TensorDataset, DataLoader, Subset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, h5py, dask.array as da\n",
        "\n",
        "data_path = '/content/drive/MyDrive/organised_data_new.h5'\n",
        "ambler_min, ambler_max = 29, 287  # inclusive\n",
        "\n",
        "# temp holders per-sample\n",
        "samples_X   = []   # list of arrays (n_frames, 20, L_i)\n",
        "samples_A   = []   # list of 1D arrays of Ambler bases kept in that sample (len L_i)\n",
        "samples_y   = []\n",
        "samples_grp = []\n",
        "\n",
        "with h5py.File(data_path, 'r') as f:\n",
        "    enzyme_names = list(f.keys())\n",
        "\n",
        "    for enzyme_id, enzyme in enumerate(f.keys()):\n",
        "        label = int(f[enzyme].attrs['carbapenemase'])\n",
        "\n",
        "        for run in f[enzyme].keys():\n",
        "            grp = f[enzyme][run]\n",
        "            probs_ds = grp['probs']                       # (n_frames, 20, n_res)\n",
        "            n_frames, _, n_res = probs_ds.shape\n",
        "            probs = da.from_array(probs_ds, chunks=(1000, 20, n_res))\n",
        "\n",
        "            amb = grp['ambler_idx'][:]                    # (n_res,)\n",
        "\n",
        "            ins = grp['ambler_ins_rank'][:] if 'ambler_ins_rank' in grp else None\n",
        "\n",
        "            # window filter\n",
        "            in_window = (amb >= ambler_min) & (amb <= ambler_max)\n",
        "\n",
        "            if ins is not None:\n",
        "                # canonical only\n",
        "                keep_mask = in_window & (ins == 0)\n",
        "                amb_cols  = amb[keep_mask].astype(int)\n",
        "                X_crop    = probs[:, :, keep_mask].compute()\n",
        "            else:\n",
        "                # no insertion ranks available\n",
        "                idxs = np.where(in_window)[0]\n",
        "                # stable “first occurrence per base” in sequence order\n",
        "                seen = set()\n",
        "                keep_idx = []\n",
        "                for i in idxs:\n",
        "                    if int(amb[i]) not in seen:\n",
        "                        seen.add(int(amb[i]))\n",
        "                        keep_idx.append(i)\n",
        "                keep_idx = np.array(keep_idx, dtype=int)\n",
        "                amb_cols = amb[keep_idx].astype(int)\n",
        "                X_crop   = probs[:, :, keep_idx].compute()\n",
        "\n",
        "            samples_X.append(X_crop)\n",
        "            samples_A.append(amb_cols)\n",
        "            samples_y.append(np.full(n_frames, label, dtype=np.int8))\n",
        "            samples_grp.append(np.full(n_frames, enzyme_id, dtype=np.int32))\n",
        "\n",
        "# align columns across samples (make seq_len identical)\n",
        "# master set = intersection of Ambler bases present in every sample\n",
        "A_master = samples_A[0].copy()\n",
        "for A_i in samples_A[1:]:\n",
        "    A_master = np.intersect1d(A_master, A_i, assume_unique=False)\n",
        "# ensure sorted ascending\n",
        "A_master = np.sort(A_master)\n",
        "\n",
        "\n",
        "# slice each sample to A_master in the same order\n",
        "X_list, y_list, g_list = [], [], []\n",
        "for X_i, A_i, y_i, g_i in zip(samples_X, samples_A, samples_y, samples_grp):\n",
        "    # map base -> column index in this sample\n",
        "    idx_map = {int(a): j for j, a in enumerate(A_i)}\n",
        "    col_idx = np.array([idx_map[a] for a in A_master], dtype=int)\n",
        "    X_list.append(X_i[:, :, col_idx])\n",
        "    y_list.append(y_i)\n",
        "    g_list.append(g_i)\n",
        "\n",
        "# final tensors\n",
        "X = np.concatenate(X_list, axis=0)            # (total_frames, 20, L)\n",
        "A = A_master                                  # (L,) Ambler bases for columns\n",
        "y = np.concatenate(y_list, axis=0)\n",
        "groups = np.concatenate(g_list, axis=0)\n",
        "\n",
        "print(\"Final dataset:\", X.shape, y.shape, groups.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJaTLFFgeVEF",
        "outputId": "0f4e3d08-6edb-4346-f276-256665cde80f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset: (120000, 20, 252) (120000,) (120000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_t = torch.from_numpy(X).float()\n",
        "y_t = torch.from_numpy(y).long()\n",
        "dataset = TensorDataset(X_t, y_t)"
      ],
      "metadata": {
        "id": "OhtS_3j3XVmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(42)\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, n_channels=20, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv1d(n_channels, 32, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(32, 64, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(2),\n",
        "\n",
        "            nn.Conv1d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool1d(1),   # [B, 128, 1]\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),              # [B, 128]\n",
        "            nn.Dropout(0.7),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.7),\n",
        "            nn.Linear(64, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5M0LbqcXXX08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "seq_len = X.shape[-1]\n",
        "\n",
        "class CNNTransformerSimple(nn.Module):\n",
        "    def __init__(self, n_channels=20, d_model=64, nhead=4, n_classes=2, seq_len=seq_len):\n",
        "        super().__init__()\n",
        "        # CNN to project 20 to d_model features per residue\n",
        "        self.conv_block = nn.Sequential(\n",
        "            nn.Conv1d(n_channels, d_model, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm1d(d_model),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv1d(d_model, d_model, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(d_model),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        # Learnable positional embeddings\n",
        "        self.pos_embed = nn.Parameter(torch.zeros(1, seq_len, d_model))\n",
        "\n",
        "        # Single-layer transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=d_model*2,\n",
        "            dropout=0.1,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
        "\n",
        "        # Global pooling + classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool1d(1),  # put seq_dim to 1\n",
        "            nn.Flatten(),             # [B, d_model]\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(d_model, d_model//2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(d_model//2, n_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # CNN block\n",
        "        h = self.conv_block(x)\n",
        "        # transpose for transformer: [B, seq_len, d_model]\n",
        "        h = h.permute(0,2,1) + self.pos_embed\n",
        "        # Transformer\n",
        "        h = self.transformer(h)           # [B, seq_len, d_model]\n",
        "        # back to [B, d_model, seq_len] and classify\n",
        "        h = h.permute(0,2,1)\n",
        "        return self.classifier(h)         # [B, n_classes]\n"
      ],
      "metadata": {
        "id": "H4u-Gz-KqN2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for test_eid in range(8):\n",
        "  print(f\"→ Testing on enzyme {test_eid}: {enzyme_names[test_eid]}\")\n",
        "  # split frame‐indices\n",
        "  train_idx = np.where(groups != test_eid)[0]\n",
        "  test_idx  = np.where(groups == test_eid)[0]\n",
        "\n",
        "  # build DataLoaders\n",
        "  BATCH = 256\n",
        "  train_loader = DataLoader(Subset(dataset, train_idx),\n",
        "                            batch_size=BATCH, shuffle=True)\n",
        "  test_loader  = DataLoader(Subset(dataset, test_idx),\n",
        "                            batch_size=BATCH)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  # set seed for reproducibility\n",
        "  torch.manual_seed(0)\n",
        "  if device.type == \"cuda\":\n",
        "      torch.cuda.manual_seed_all(0)\n",
        "\n",
        "  # lossf = nn.CrossEntropyLoss()\n",
        "\n",
        "  model = CNNTransformerSimple().to(device)\n",
        "  # model = SmallCNN().to(device)\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "  EPOCHS = 10\n",
        "  for epoch in range(1, EPOCHS+1):\n",
        "      model.train()\n",
        "      acc_sum = loss_sum = n = 0\n",
        "      for xb, yb in train_loader:\n",
        "          xb, yb = xb.to(device), yb.to(device)\n",
        "          opt.zero_grad()\n",
        "          logits = model(xb)\n",
        "          loss   = criterion(logits, yb)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "\n",
        "          loss_sum += loss.item() * xb.size(0)\n",
        "          acc_sum  += (logits.argmax(1) == yb).sum().item()\n",
        "          n       += xb.size(0)\n",
        "\n",
        "      # print(f\"Epoch {epoch:02d}  \"\n",
        "      #       f\"Train Loss: {loss_sum/n:.4f}, \"\n",
        "      #       f\"Train Acc:  {acc_sum/n:.4f}\")\n",
        "\n",
        "  # final test eval\n",
        "  model.eval()\n",
        "  correct = total = 0\n",
        "  with torch.no_grad():\n",
        "      for xb, yb in test_loader:\n",
        "          xb, yb = xb.to(device), yb.to(device)\n",
        "          preds = model(xb).argmax(1)\n",
        "          correct += (preds == yb).sum().item()\n",
        "          total   += xb.size(0)\n",
        "\n",
        "  print(f\"Test on {enzyme_names[test_eid]}  Acc: {correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "wkG6my4CGLvW",
        "outputId": "4c409632-4644-43f2-e6f1-2b048e1d871e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'enzyme_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2611796705.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_eid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"→ Testing on enzyme {test_eid}: {enzyme_names[test_eid]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;31m# split frame‐indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtrain_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtest_eid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtest_idx\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtest_eid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'enzyme_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Wrap entire dataset\n",
        "full_loader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# set seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "model = CNNTransformerSimple().to(device)\n",
        "# model = SmallCNN().to(device)\n",
        "lossf = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "# Train for N epochs\n",
        "EPOCHS = 10\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    total_loss = total_correct = total = 0\n",
        "    for xb, yb in full_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        opt.zero_grad()\n",
        "        logits = model(xb)\n",
        "        loss   = lossf(logits, yb)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        total_loss   += loss.item() * xb.size(0)\n",
        "        total_correct+= (logits.argmax(1) == yb).sum().item()\n",
        "        total        += xb.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch:02d} | Loss: {total_loss/total:.4f} | Acc: {total_correct/total:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4wZIoOEXa8B",
        "outputId": "52845b2c-2eef-4ce7-ac0e-e0280898f2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Loss: 0.0251 | Acc: 0.9925\n",
            "Epoch 02 | Loss: 0.0003 | Acc: 0.9999\n",
            "Epoch 03 | Loss: 0.0001 | Acc: 1.0000\n",
            "Epoch 04 | Loss: 0.0000 | Acc: 1.0000\n",
            "Epoch 05 | Loss: 0.0000 | Acc: 1.0000\n",
            "Epoch 06 | Loss: 0.0000 | Acc: 1.0000\n",
            "Epoch 07 | Loss: 0.0000 | Acc: 1.0000\n",
            "Epoch 08 | Loss: 0.0000 | Acc: 1.0000\n",
            "Epoch 09 | Loss: 0.0000 | Acc: 1.0000\n",
            "Epoch 10 | Loss: 0.0000 | Acc: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from captum.attr import (\n",
        "    Saliency,\n",
        "    IntegratedGradients,\n",
        "    NoiseTunnel,\n",
        "    DeepLift,\n",
        "    LayerGradCam\n",
        ")"
      ],
      "metadata": {
        "id": "75s_H5nQu_A5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "# Prepare data loader\n",
        "dataset = TensorDataset(X_t, y_t)\n",
        "loader  = DataLoader(dataset, batch_size=256, shuffle=True)\n",
        "\n",
        "# Captum attributions\n",
        "saliency    = Saliency(model)\n",
        "ig          = IntegratedGradients(model)\n",
        "nt          = NoiseTunnel(saliency)\n",
        "deeplift    = DeepLift(model)\n",
        "\n",
        "# Grad‑CAM on the second conv layer\n",
        "target_layer = model.conv_block[3]\n",
        "gradcam      = LayerGradCam(model, target_layer)\n",
        "\n",
        "# baseline for IG/DeepLIFT: uniform distribution\n",
        "baseline = torch.zeros(1, 20, seq_len, device=device) + (1.0/20.0)\n",
        "\n",
        "# Compute attributions\n",
        "methods = {\n",
        "    'saliency': lambda inp: saliency.attribute(inp, target=1),\n",
        "    'smooth':   lambda inp: nt.attribute(inp, target=1,\n",
        "                        nt_type='smoothgrad', stdevs=0.02, nt_samples=25),\n",
        "    'ig':       lambda inp: ig.attribute(inp, baselines=baseline,\n",
        "                        target=1, n_steps=100),\n",
        "    'deeplift': lambda inp: deeplift.attribute(inp, baselines=baseline, target=1),\n",
        "    'gradcam':  lambda inp: gradcam.attribute(inp, target=1)\n",
        "}\n",
        "\n",
        "scores = {name: [] for name in methods}\n",
        "max_frames = 500\n",
        "count = 0\n",
        "\n",
        "for X_batch, _ in loader:\n",
        "    X_batch = X_batch.to(device)\n",
        "    for frame in X_batch:\n",
        "        inp = frame.unsqueeze(0).requires_grad_(True)\n",
        "        for name, fn in methods.items():\n",
        "            attr = fn(inp)\n",
        "            if name == 'gradcam':\n",
        "                # [1,d_model,seq_len] mean over d_model\n",
        "                res = attr.mean(dim=1).squeeze(0)\n",
        "            else:\n",
        "                # [1,20,seq_len] sum over AAs\n",
        "                res = attr.abs().sum(dim=1).squeeze(0)\n",
        "            scores[name].append(res.cpu().detach())\n",
        "        count += 1\n",
        "        if count >= max_frames:\n",
        "            break\n",
        "    if count >= max_frames:\n",
        "        break\n",
        "\n",
        "# Average and normalise top residues\n",
        "top_k = 10\n",
        "for name, arr in scores.items():\n",
        "    stacked = torch.stack(arr)               # [max_frames, seq_len]\n",
        "    avg_imp = stacked.mean(dim=0)\n",
        "    norm_imp = (avg_imp - avg_imp.min()) / (avg_imp.max() - avg_imp.min() + 1e-8)\n",
        "    vals, idxs = torch.topk(norm_imp, k=top_k)\n",
        "    print(f\"\\n{name.upper()} Top Ambler residues:\", A[idxs.cpu().numpy()].tolist())\n",
        "    print(f\"{name.upper()} Scores: {vals.tolist()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEil87Zyu5Nu",
        "outputId": "48bbf0fd-2c77-4ca3-dfa2-094796ad9179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SALIENCY Top Ambler residues (0‑based): [238, 239, 241, 240, 237, 236, 242, 235, 243, 234]\n",
            "SALIENCY Scores: [1.0, 0.9371141195297241, 0.811948835849762, 0.7939862608909607, 0.6581747531890869, 0.6459794640541077, 0.6450086832046509, 0.6336749196052551, 0.554413914680481, 0.5061284899711609]\n",
            "\n",
            "SMOOTH Top Ambler residues (0‑based): [238, 239, 241, 240, 237, 242, 236, 235, 243, 234]\n",
            "SMOOTH Scores: [1.0, 0.9396723508834839, 0.8151755332946777, 0.7927833199501038, 0.6589153409004211, 0.6503751277923584, 0.6456523537635803, 0.6320083141326904, 0.557887852191925, 0.5089046359062195]\n",
            "\n",
            "IG Top Ambler residues (0‑based): [241, 238, 240, 236, 239, 244, 242, 235, 60, 237]\n",
            "IG Scores: [1.0, 0.9314240217208862, 0.9175805449485779, 0.5742488503456116, 0.41367408633232117, 0.363450288772583, 0.36319872736930847, 0.2897765338420868, 0.2771315276622772, 0.2668672800064087]\n",
            "\n",
            "DEEPLIFT Top Ambler residues (0‑based): [240, 241, 238, 236, 239, 242, 244, 235, 243, 237]\n",
            "DEEPLIFT Scores: [1.0, 0.9810715317726135, 0.9343883395195007, 0.45583024621009827, 0.41153624653816223, 0.379379540681839, 0.3589443266391754, 0.2720070779323578, 0.2322055548429489, 0.2311488837003708]\n",
            "\n",
            "GRADCAM Top Ambler residues (0‑based): [240, 174, 222, 56, 221, 225, 45, 223, 156, 173]\n",
            "GRADCAM Scores: [0.9999992251396179, 0.9075402021408081, 0.8794172406196594, 0.8701099753379822, 0.8437827229499817, 0.8361417651176453, 0.8117186427116394, 0.7963617444038391, 0.7951096892356873, 0.7851399779319763]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------------------"
      ],
      "metadata": {
        "id": "Fo0a_oFjb24d"
      }
    }
  ]
}